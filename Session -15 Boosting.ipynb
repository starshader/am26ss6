{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e999fe5",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad07141",
   "metadata": {},
   "source": [
    "Boosting\n",
    "\n",
    "Different techiques:\n",
    "\n",
    "     AdaBoost\n",
    "     \n",
    "     GradientBoost\n",
    "     \n",
    "     XGBoost\n",
    "\n",
    "Use diabetes for implementing these\n",
    "\n",
    "Find the best models by hyper parameter tuning\n",
    "\n",
    "Compare and choose the best\n",
    "\n",
    "Use that to give inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3533e6b",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "https://www.youtube.com/watch?v=LsK-xG1cLYA&t=614s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a1e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57c9ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db=pd.read_csv('diabetes.csv')\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efed5b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63994726,  0.84832379,  0.14964075, ...,  0.20401277,\n",
       "         0.46849198,  1.4259954 ],\n",
       "       [-0.84488505, -1.12339636, -0.16054575, ..., -0.68442195,\n",
       "        -0.36506078, -0.19067191],\n",
       "       [ 1.23388019,  1.94372388, -0.26394125, ..., -1.10325546,\n",
       "         0.60439732, -0.10558415],\n",
       "       ...,\n",
       "       [ 0.3429808 ,  0.00330087,  0.14964075, ..., -0.73518964,\n",
       "        -0.68519336, -0.27575966],\n",
       "       [-0.84488505,  0.1597866 , -0.47073225, ..., -0.24020459,\n",
       "        -0.37110101,  1.17073215],\n",
       "       [-0.84488505, -0.8730192 ,  0.04624525, ..., -0.20212881,\n",
       "        -0.47378505, -0.87137393]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=db['Outcome']\n",
    "X=db.drop(['Outcome'],axis=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3de9762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (154, 8), (614,), (154,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.2, random_state=10)\n",
    "\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981015f",
   "metadata": {},
   "source": [
    "## Building- AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020aef52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc=AdaBoostClassifier(random_state=10)\n",
    "\n",
    "abc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9e8a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.81        95\n",
      "           1       0.73      0.51      0.60        59\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.74      0.70      0.70       154\n",
      "weighted avg       0.74      0.74      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report= classification_report(y_test,abc.predict(X_test))\n",
    "print('Report:\\n',report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6076bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "abc_gs=GridSearchCV(abc,{'n_estimators':range(25,75),\n",
    "                        'learning_rate':[0,0.25,0.5,0.75,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "531ba2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "250 fits failed out of a total of 1250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 486, in fit\n",
      "    return super().fit(X, y, sample_weight)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py\", line 114, in fit\n",
      "    raise ValueError(\"learning_rate must be greater than zero\")\n",
      "ValueError: learning_rate must be greater than zero\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.76061575 0.76386779 0.76060243 0.76222844\n",
      " 0.76222844 0.7605891  0.75896308 0.76221511 0.76057577 0.76221511\n",
      " 0.75732374 0.75732374 0.7605891  0.76060243 0.76060243 0.76060243\n",
      " 0.76060243 0.76385446 0.76222844 0.76874583 0.76874583 0.76873251\n",
      " 0.76385446 0.76385446 0.76548047 0.76710649 0.77199787 0.77199787\n",
      " 0.77362388 0.77362388 0.77199787 0.77037185 0.77199787 0.77037185\n",
      " 0.77037185 0.77037185 0.76874583 0.77199787 0.77199787 0.77199787\n",
      " 0.77199787 0.77037185 0.77037185 0.77037185 0.77199787 0.77199787\n",
      " 0.76873251 0.77035852 0.77035852 0.77198454 0.75572438 0.75245902\n",
      " 0.75408503 0.75896308 0.75735039 0.76385446 0.76548047 0.76060243\n",
      " 0.76548047 0.76385446 0.76221511 0.76546715 0.7605891  0.76221511\n",
      " 0.76384113 0.75733707 0.75733707 0.75733707 0.75571105 0.76221511\n",
      " 0.75896308 0.7605891  0.75896308 0.75733707 0.75408503 0.75408503\n",
      " 0.75408503 0.750833   0.75408503 0.75081967 0.75244569 0.75733707\n",
      " 0.75733707 0.75896308 0.75733707 0.75571105 0.75733707 0.75735039\n",
      " 0.76060243 0.7654938  0.7654938  0.7654938  0.76386779 0.7654938\n",
      " 0.7622551  0.76062908 0.75572438 0.75735039 0.76064241 0.76389444\n",
      " 0.75405838 0.75080634 0.75732374 0.75733707 0.75569772 0.75732374\n",
      " 0.75081967 0.7459283  0.75245902 0.75081967 0.74268959 0.75245902\n",
      " 0.74756764 0.75247234 0.75897641 0.75572438 0.75572438 0.75732374\n",
      " 0.75568439 0.75894975 0.75569772 0.75571105 0.75408503 0.75571105\n",
      " 0.75408503 0.75733707 0.75896308 0.7540717  0.75405838 0.75893643\n",
      " 0.75404505 0.7605891  0.75733707 0.76221511 0.7605891  0.75732374\n",
      " 0.7540717  0.75569772 0.75077969 0.75241903 0.74752766 0.75243236\n",
      " 0.75569772 0.7540717  0.7540717  0.75408503 0.75572438 0.76060243\n",
      " 0.75572438 0.76060243 0.75564441 0.74588831 0.75889644 0.7621618\n",
      " 0.75728375 0.75728375 0.75569772 0.75569772 0.74752766 0.7540717\n",
      " 0.75243236 0.75405838 0.75079302 0.75894975 0.75731041 0.75569772\n",
      " 0.75735039 0.75569772 0.75241903 0.75079302 0.75404505 0.74427562\n",
      " 0.74430228 0.74755431 0.74755431 0.74918033 0.74755431 0.74590164\n",
      " 0.75080634 0.74266293 0.75245902 0.74594162 0.75247234 0.749167\n",
      " 0.74591497 0.74754098 0.75243236 0.75732374 0.75080634 0.75896308\n",
      " 0.75572438 0.75569772 0.75080634 0.75731041 0.75077969 0.749167\n",
      " 0.7524057  0.749167   0.74427562 0.74752766]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=AdaBoostClassifier(random_state=10),\n",
       "             param_grid={'learning_rate': [0, 0.25, 0.5, 0.75, 1],\n",
       "                         'n_estimators': range(25, 75)})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa6f598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.25, 'n_estimators': 53}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b4f988d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.25, n_estimators=53, random_state=10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the best model using these values\n",
    "\n",
    "ada_best=AdaBoostClassifier(learning_rate=0.25,n_estimators=53,random_state=10)\n",
    "\n",
    "ada_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67964300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.94      0.84        95\n",
      "           1       0.83      0.51      0.63        59\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.79      0.72      0.73       154\n",
      "weighted avg       0.78      0.77      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report=classification_report(y_test,ada_best.predict(X_test))\n",
    "\n",
    "print('Report:\\n',report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea34e7",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6b82b",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=jxuNLH5dXCs&t=855s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b72d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91d3dc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc=GradientBoostingClassifier(random_state=10)\n",
    "\n",
    "gbc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "447574cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84        95\n",
      "           1       0.78      0.61      0.69        59\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.78      0.75      0.76       154\n",
      "weighted avg       0.79      0.79      0.78       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report=classification_report(y_test,gbc.predict(X_test))\n",
    "\n",
    "print('Report:\\n',report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "846cd94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning\n",
    "\n",
    "gbc_gs=GridSearchCV(gbc,{'n_estimators':range(75,125),\n",
    "                        'max_depth':range(1,5),\n",
    "                        'learning_rate':[0,0.25,.5,.75,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d0b5b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "1000 fits failed out of a total of 5000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 274, in _check_params\n",
      "    raise ValueError(\n",
      "ValueError: learning_rate must be greater than 0 but was 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.77359723 0.76871918 0.77359723 0.77359723\n",
      " 0.77359723 0.7703452  0.77197121 0.77197121 0.77197121 0.77197121\n",
      " 0.7703452  0.7703452  0.7703452  0.7703452  0.76546715 0.76709316\n",
      " 0.76871918 0.76871918 0.76709316 0.76546715 0.76546715 0.76871918\n",
      " 0.76546715 0.76546715 0.76546715 0.76871918 0.76709316 0.76709316\n",
      " 0.76546715 0.76546715 0.76709316 0.76709316 0.76871918 0.76871918\n",
      " 0.76871918 0.7703452  0.76871918 0.76221511 0.76871918 0.76709316\n",
      " 0.76871918 0.76546715 0.76548047 0.76709316 0.76871918 0.76546715\n",
      " 0.76384113 0.76546715 0.76548047 0.76221511 0.76386779 0.76550713\n",
      " 0.76388111 0.76550713 0.76550713 0.76713315 0.7622551  0.7622551\n",
      " 0.7622551  0.76224177 0.76060243 0.75733707 0.75735039 0.75735039\n",
      " 0.75735039 0.75733707 0.75897641 0.76386779 0.76060243 0.75733707\n",
      " 0.75567106 0.75404505 0.75731041 0.75893643 0.75568439 0.75731041\n",
      " 0.75567106 0.75732374 0.75405838 0.75405838 0.75568439 0.7540717\n",
      " 0.75405838 0.75568439 0.75568439 0.75405838 0.75568439 0.75405838\n",
      " 0.75243236 0.75405838 0.75243236 0.75243236 0.75733707 0.75896308\n",
      " 0.76546715 0.76384113 0.76384113 0.76060243 0.76060243 0.76060243\n",
      " 0.75571105 0.75245902 0.75409836 0.75247234 0.75736372 0.75409836\n",
      " 0.75572438 0.75735039 0.76062908 0.76062908 0.7622551  0.76388111\n",
      " 0.76388111 0.7622551  0.7622551  0.76060243 0.76222844 0.76385446\n",
      " 0.76385446 0.76711982 0.76710649 0.76548047 0.76875916 0.7654938\n",
      " 0.76385446 0.76548047 0.76386779 0.76385446 0.75572438 0.75897641\n",
      " 0.75897641 0.75571105 0.75733707 0.76060243 0.76222844 0.7605891\n",
      " 0.76224177 0.76386779 0.76224177 0.76386779 0.76385446 0.7654938\n",
      " 0.76386779 0.7654938  0.76548047 0.76874583 0.76873251 0.7654938\n",
      " 0.76386779 0.76713315 0.7296548  0.72476343 0.72640277 0.73129415\n",
      " 0.7361722  0.73290684 0.73128082 0.73778489 0.73290684 0.73453285\n",
      " 0.73289351 0.72964148 0.73126749 0.72800213 0.7345062  0.72962815\n",
      " 0.73125417 0.73125417 0.73613221 0.73613221 0.73613221 0.73611889\n",
      " 0.73449287 0.73286685 0.73124084 0.73124084 0.72961482 0.72797548\n",
      " 0.72797548 0.72797548 0.72960149 0.72797548 0.72797548 0.73122751\n",
      " 0.73124084 0.72960149 0.73122751 0.73285353 0.73122751 0.73285353\n",
      " 0.73446621 0.73121418 0.72958816 0.72633613 0.72958816 0.7328402\n",
      " 0.72958816 0.73449287 0.73449287 0.7345062  0.75897641 0.75572438\n",
      " 0.75571105 0.75735039 0.76060243 0.76222844 0.76060243 0.75572438\n",
      " 0.75408503 0.75736372 0.75736372 0.75736372 0.76061575 0.75898974\n",
      " 0.75735039 0.75898974 0.75736372 0.75898974 0.75411169 0.7557377\n",
      " 0.75411169 0.7557377  0.75411169 0.75248567 0.75248567 0.75084633\n",
      " 0.750833   0.75084633 0.750833   0.75084633 0.74758097 0.75247234\n",
      " 0.74758097 0.74920698 0.74920698 0.75084633 0.75084633 0.75084633\n",
      " 0.750833   0.75084633 0.75409836 0.75409836 0.75735039 0.75572438\n",
      " 0.75409836 0.75572438 0.75572438 0.75409836 0.75572438 0.75247234\n",
      " 0.750833   0.74595495 0.75571105 0.75733707 0.75408503 0.750833\n",
      " 0.74920698 0.74758097 0.74595495 0.74432894 0.7475943  0.74271625\n",
      " 0.74432894 0.74432894 0.74270292 0.7410769  0.73945089 0.73455951\n",
      " 0.73781154 0.73782487 0.73781154 0.73945089 0.73945089 0.73781154\n",
      " 0.73943756 0.73782487 0.73457284 0.73130748 0.73293349 0.73293349\n",
      " 0.73293349 0.73943756 0.73454618 0.73943756 0.74106357 0.73942423\n",
      " 0.7459283  0.7459283  0.74919366 0.74919366 0.74431561 0.74919366\n",
      " 0.74919366 0.75081967 0.74919366 0.75244569 0.75569772 0.75894975\n",
      " 0.75894975 0.76057577 0.75408503 0.75244569 0.75245902 0.750833\n",
      " 0.75408503 0.75896308 0.75897641 0.75569772 0.76061575 0.75572438\n",
      " 0.76060243 0.76060243 0.76060243 0.75569772 0.75896308 0.75896308\n",
      " 0.7605891  0.75896308 0.75733707 0.75896308 0.75733707 0.75733707\n",
      " 0.75732374 0.7605891  0.76221511 0.75732374 0.75569772 0.75408503\n",
      " 0.75245902 0.7557377  0.75900307 0.76062908 0.7622551  0.76550713\n",
      " 0.76388111 0.76060243 0.75408503 0.75245902 0.75733707 0.75733707\n",
      " 0.75245902 0.75408503 0.75408503 0.7605891  0.75896308 0.7605891\n",
      " 0.76221511 0.76710649 0.76222844 0.76060243 0.74263628 0.74588831\n",
      " 0.74263628 0.74101026 0.74101026 0.73938425 0.73938425 0.73613221\n",
      " 0.74263628 0.74588831 0.74751433 0.74424897 0.74262295 0.7442623\n",
      " 0.74590164 0.74428895 0.74428895 0.74266293 0.74431561 0.74594162\n",
      " 0.74431561 0.74594162 0.73943756 0.73781154 0.74267626 0.74267626\n",
      " 0.73778489 0.73778489 0.74431561 0.73779821 0.7361722  0.73454618\n",
      " 0.73779821 0.73128082 0.73290684 0.73615887 0.7361722  0.7361722\n",
      " 0.73781154 0.73943756 0.73942423 0.74106357 0.74106357 0.74268959\n",
      " 0.74267626 0.7394109  0.74105025 0.7394109  0.7394109  0.73778489\n",
      " 0.75571105 0.75733707 0.75408503 0.7540717  0.75409836 0.75571105\n",
      " 0.75735039 0.7605891  0.75735039 0.75405838 0.75080634 0.75243236\n",
      " 0.7540717  0.75081967 0.74919366 0.75244569 0.74919366 0.74755431\n",
      " 0.74918033 0.75081967 0.74754098 0.75244569 0.74918033 0.75081967\n",
      " 0.74919366 0.7459283  0.74758097 0.74428895 0.74430228 0.74266293\n",
      " 0.74267626 0.74591497 0.74428895 0.73939757 0.74590164 0.74264961\n",
      " 0.74266293 0.73777156 0.7394109  0.73451953 0.7394109  0.73777156\n",
      " 0.73614554 0.73939757 0.73615887 0.74266293 0.73942423 0.73943756\n",
      " 0.73778489 0.73454618 0.75243236 0.75244569 0.75080634 0.74918033\n",
      " 0.75079302 0.74915367 0.74588831 0.74915367 0.73938425 0.74264961\n",
      " 0.74754098 0.749167   0.74754098 0.75077969 0.74751433 0.74588831\n",
      " 0.75081967 0.75243236 0.75405838 0.75080634 0.749167   0.749167\n",
      " 0.75404505 0.75405838 0.75243236 0.75731041 0.75731041 0.75893643\n",
      " 0.75405838 0.75079302 0.75079302 0.75241903 0.75405838 0.75731041\n",
      " 0.75893643 0.75079302 0.749167   0.74590164 0.74590164 0.74754098\n",
      " 0.74915367 0.74915367 0.75079302 0.75077969 0.7524057  0.75239238\n",
      " 0.75729708 0.75077969 0.74915367 0.74915367 0.75081967 0.74918033\n",
      " 0.74919366 0.75736372 0.75409836 0.74920698 0.74595495 0.74434226\n",
      " 0.7475943  0.74758097 0.74756764 0.74758097 0.74758097 0.75084633\n",
      " 0.750833   0.75572438 0.75084633 0.750833   0.75245902 0.74922031\n",
      " 0.7475943  0.74596828 0.74596828 0.74596828 0.75572438 0.75409836\n",
      " 0.75409836 0.74922031 0.74922031 0.74922031 0.74922031 0.74922031\n",
      " 0.75247234 0.75247234 0.75084633 0.75411169 0.7557377  0.75247234\n",
      " 0.74758097 0.74920698 0.74920698 0.7475943  0.75084633 0.75084633\n",
      " 0.7475943  0.74596828 0.74923364 0.75085966 0.74923364 0.74758097\n",
      " 0.73779821 0.7394109  0.74266293 0.74428895 0.74428895 0.74264961\n",
      " 0.73614554 0.73939757 0.74264961 0.74590164 0.74591497 0.74267626\n",
      " 0.74428895 0.74102359 0.74103692 0.74428895 0.74428895 0.75079302\n",
      " 0.75079302 0.75405838 0.75080634 0.75080634 0.74919366 0.74918033\n",
      " 0.74755431 0.75080634 0.74755431 0.74918033 0.74266293 0.74591497\n",
      " 0.74430228 0.74266293 0.74594162 0.74268959 0.74266293 0.74267626\n",
      " 0.74428895 0.74918033 0.75244569 0.75244569 0.75243236 0.75241903\n",
      " 0.75079302 0.75079302 0.75079302 0.74915367 0.74915367 0.74918033\n",
      " 0.75244569 0.74430228 0.74264961 0.73613221 0.73775823 0.73777156\n",
      " 0.73614554 0.74102359 0.74266293 0.73775823 0.74427562 0.73775823\n",
      " 0.73938425 0.74427562 0.73613221 0.74103692 0.74102359 0.74266293\n",
      " 0.7459283  0.74266293 0.74102359 0.74591497 0.73938425 0.74591497\n",
      " 0.74591497 0.74591497 0.74263628 0.74101026 0.74590164 0.7442623\n",
      " 0.74102359 0.74588831 0.73938425 0.73775823 0.73775823 0.73613221\n",
      " 0.74103692 0.73778489 0.7394109  0.73778489 0.73781154 0.73781154\n",
      " 0.73781154 0.73455951 0.73943756 0.73290684 0.73778489 0.73613221\n",
      " 0.73939757 0.73451953 0.73938425 0.73289351 0.72473677 0.72473677\n",
      " 0.72964148 0.72800213 0.7247501  0.7247501  0.7247501  0.72312408\n",
      " 0.71987205 0.7215114  0.71988538 0.71825936 0.72152472 0.71827269\n",
      " 0.71989871 0.71827269 0.71338131 0.71500733 0.71502066 0.71989871\n",
      " 0.71989871 0.71502066 0.71662002 0.71825936 0.72477676 0.71989871\n",
      " 0.71989871 0.72315074 0.72152472 0.71827269 0.72152472 0.71989871\n",
      " 0.72315074 0.72802879 0.72477676 0.72640277 0.72801546 0.72801546\n",
      " 0.72638944 0.72801546 0.72801546 0.72802879 0.72640277 0.72640277\n",
      " 0.72802879 0.72640277 0.72640277 0.7296548  0.72802879 0.7215114\n",
      " 0.74595495 0.74758097 0.74595495 0.74432894 0.74268959 0.74267626\n",
      " 0.74756764 0.74268959 0.74594162 0.74920698 0.74758097 0.75572438\n",
      " 0.75248567 0.75411169 0.74756764 0.75085966 0.74595495 0.74432894\n",
      " 0.7394109  0.74591497 0.74755431 0.74756764 0.74756764 0.74428895\n",
      " 0.74430228 0.73939757 0.74102359 0.73938425 0.74428895 0.74430228\n",
      " 0.74268959 0.74268959 0.74106357 0.73778489 0.74267626 0.74105025\n",
      " 0.74266293 0.74428895 0.74594162 0.74431561 0.74432894 0.74270292\n",
      " 0.73779821 0.74596828 0.74922031 0.74434226 0.75409836 0.74920698\n",
      " 0.74922031 0.74922031 0.7459283  0.7459283  0.74268959 0.73781154\n",
      " 0.74106357 0.73943756 0.73942423 0.74105025 0.75080634 0.73942423\n",
      " 0.73943756 0.7361722  0.74106357 0.74594162 0.74431561 0.7459283\n",
      " 0.74594162 0.74267626 0.74595495 0.7475943  0.74432894 0.74432894\n",
      " 0.74431561 0.74431561 0.74431561 0.74431561 0.74267626 0.74431561\n",
      " 0.74758097 0.74268959 0.74758097 0.74919366 0.74595495 0.75245902\n",
      " 0.750833   0.75248567 0.74595495 0.74920698 0.75409836 0.75735039\n",
      " 0.7540717  0.75571105 0.75245902 0.75245902 0.74920698 0.74595495\n",
      " 0.750833   0.74756764 0.750833   0.74595495]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingClassifier(random_state=10),\n",
       "             param_grid={'learning_rate': [0, 0.25, 0.5, 0.75, 1],\n",
       "                         'max_depth': range(1, 5),\n",
       "                         'n_estimators': range(75, 125)})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "338c1061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.25, 'max_depth': 1, 'n_estimators': 75}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b25eaf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the best\n",
    "grad_best=GradientBoostingClassifier(learning_rate=0.25,max_depth=1, n_estimators=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01980763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.25, max_depth=1, n_estimators=75)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eb3cc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.92      0.82        95\n",
      "           1       0.78      0.49      0.60        59\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.76      0.70      0.71       154\n",
      "weighted avg       0.76      0.75      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report=classification_report(y_test,grad_best.predict(X_test))\n",
    "\n",
    "print('Report:\\n',report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f1153",
   "metadata": {},
   "source": [
    "## XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30c57a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e5f7356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f114812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:10:53] WARNING: /var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_44tbtwf8c1/croots/recipe/xgboost-split_1659548960882/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg=XGBClassifier()\n",
    "xg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bac2c0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76        95\n",
      "           1       0.62      0.58      0.60        59\n",
      "\n",
      "    accuracy                           0.70       154\n",
      "   macro avg       0.68      0.68      0.68       154\n",
      "weighted avg       0.70      0.70      0.70       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report=classification_report(y_test,xg.predict(X_test))\n",
    "print('Report:\\n',report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a83824f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the hyper parameter tuning\n",
    "\n",
    "# Form the best XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe12f0e",
   "metadata": {},
   "source": [
    "## Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35ce2971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04102228, 0.41813537, 0.04903082, 0.02484091, 0.04675064,\n",
       "       0.16272107, 0.11241005, 0.14508886])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The best result offerd by gbc\n",
    "\n",
    "gbc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a93139e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.041022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.418135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.049031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.024841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.046751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.162721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.112410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.145089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature       Imp\n",
       "0               Pregnancies  0.041022\n",
       "1                   Glucose  0.418135\n",
       "2             BloodPressure  0.049031\n",
       "3             SkinThickness  0.024841\n",
       "4                   Insulin  0.046751\n",
       "5                       BMI  0.162721\n",
       "6  DiabetesPedigreeFunction  0.112410\n",
       "7                       Age  0.145089"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Feature':X.columns,\n",
    "                'Imp':gbc.feature_importances_})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "621d5e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glucose</td>\n",
       "      <td>0.418135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BMI</td>\n",
       "      <td>0.162721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.145089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DiabetesPedigreeFunction</td>\n",
       "      <td>0.112410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BloodPressure</td>\n",
       "      <td>0.049031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulin</td>\n",
       "      <td>0.046751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pregnancies</td>\n",
       "      <td>0.041022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SkinThickness</td>\n",
       "      <td>0.024841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Feature       Imp\n",
       "1                   Glucose  0.418135\n",
       "5                       BMI  0.162721\n",
       "7                       Age  0.145089\n",
       "6  DiabetesPedigreeFunction  0.112410\n",
       "2             BloodPressure  0.049031\n",
       "4                   Insulin  0.046751\n",
       "0               Pregnancies  0.041022\n",
       "3             SkinThickness  0.024841"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sort_values(['Imp'],ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0192c7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=df['Imp'],y=df['Feature'],data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be60e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
