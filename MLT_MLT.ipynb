{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=pd.read_csv('A')\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns:\n",
    "db.drop(['C1','C2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding null values:\n",
    "db.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows with some constraint:\n",
    "db1=db[db['C4']<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical to numerical features\n",
    "# One hot encoding\n",
    "db1=pd.get_dummies(db,columns=['C1','C2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values:\n",
    "db['A'].fillna(db['A'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation or standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "db = scaler.fit_transform(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split:\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(db,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape, xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(),annot=True,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df,x='Customer Type',hue='satisfaction') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.histplot(data=df,x='Flight Distance',hue='Class',palette='RdYlGn_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.boxplot(data=df,y='Flight Distance',x='Leg room service')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) SLR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sal['YearsExperience']\n",
    "Y=sal['Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "slr = sm.OLS(ytrain,xtrain)\n",
    "\n",
    "#Regression coefficients and summary:\n",
    "model.params\n",
    "model.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting :\n",
    "Y_pred=lr.predict(X_test.to_numpy().reshape(-1,1))\n",
    "\n",
    "plt.scatter(X_train,Y_train,c='green');\n",
    "plt.scatter(X_test,Y_test,c='pink');\n",
    "plt.plot(X_test,Y_pred,c='blue') # plotting the model so Y_pred\n",
    "plt.xlabel('Years of Experience')\n",
    "plt.ylabel('Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form equation of regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) MLR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "y=ipl['SOLD PRICE']\n",
    "\n",
    "# Features\n",
    "X=ipl.drop(['SOLD PRICE'],axis=1)\n",
    "\n",
    "X.head()\n",
    "#Drop irrelevant columns on the value of p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building:\n",
    "mlr_1=sm.OLS(y_train_1,X_train_1)\n",
    "\n",
    "# Fitting\n",
    "mlr_1=mlr_1.fit()\n",
    "\n",
    "model.params\n",
    "model.summary2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF, heatmap-drop-iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Performance measures for Regression:\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "ypred = mlr.predict(xtest)\n",
    "r2_mlr = r2_score(ytest,ypred)\n",
    "mse = mean_squared_error(ytest,ypred)\n",
    "np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= gc['Creditability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()\n",
    "X=gc.drop(['Creditability'],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1.iloc[0:10,60:]import statsmodels.api as sm\n",
    "logR = sm.Logit(ytrain,xtrain)\n",
    "logR = logR.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose significant feature from summary 2:\n",
    "signi_features_1=['Duration of Credit (month)','Credit Amount',\n",
    "                 'Age (years)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2=X_1[signi_features_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred= logR.predict(xtest)\n",
    "pred_df=pd.DataFrame({'Actual Class':y1_test,\n",
    "                     'Predicted Prob': ypred})\n",
    "pred_df['Predicted Class']=pred_df['Predicted Prob'].map(lambda x: 1 if x>0.5 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(pred_df['Actual Class'],pred_df['Predicted Class'])\n",
    "report=classification_report(pred_df['Actual Class'],pred_df['Predicted Class'])\n",
    "score=roc_auc_score(pred_df['Actual Class'],pred_df['Predicted Class'])\n",
    "print(' Confusion Matrix:\\n',cm)\n",
    "print(' The report:\\n',report)\n",
    "print(' Score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr,tpr,threshold=roc_curve(pred_df['Actual Class'],\n",
    "                           pred_df['Predicted Prob'])\n",
    "\n",
    "plt.plot(fpr,tpr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr,tpr);\n",
    "plt.plot([0,1],[0,1],color='r')\n",
    "plt.xlabel(' FPR')\n",
    "plt.ylabel('TPR');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area under the roc curve\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score= roc_auc_score(pred_df['Actual Class'],\n",
    "                           pred_df['Predicted Prob'])\n",
    "\n",
    "print(' ROC-AUC-Score:',score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youden's index= Max( senstivity + specificity - 1)\n",
    "\n",
    "              = Max( senstivity - (1-  specificity)\n",
    "              \n",
    "              = Max (FPR - TPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DF\n",
    "\n",
    "fpr_tpr=pd.DataFrame({'FPR':fpr,\n",
    "                     'TPR':tpr,\n",
    "                     'Threshold':threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tpr['Diff']=fpr_tpr['TPR']-fpr_tpr['FPR']\n",
    "fpr_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_tpr.sort_values('Diff',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['New Predicted Class']=pred_df['Predicted Prob'].map(lambda x: 1 if x>0.526841 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_new= confusion_matrix(pred_df['Actual Class'],\n",
    "                        pred_df['New Predicted Class'])\n",
    "\n",
    "print('The new confusion matrix:\\n', cm_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_new=roc_auc_score(pred_df['Actual Class'],\n",
    "                       pred_df['New Predicted Class'])\n",
    "print('The new ROC-AUC-Score',score_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=db['Outcome']\n",
    "y.head()\n",
    "y.value_counts()\n",
    "X=db.drop(['Outcome'],axis=1)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_linoh=SVC(kernel='linear',probability=True)\n",
    "svc_linoh=svc_linoh.fit(xt,Yt)\n",
    "y_pred=svc_linoh.predict(xT)\n",
    "y_pred_prob=svc_linoh.predict_proba(xT)\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "report=classification_report(y_test,y_pred)\n",
    "score=roc_auc_score(y_test,y_pred)\n",
    "print(' Confusion Matrix:\\n',cm)\n",
    "print(' The report:\\n',report)\n",
    "print(' Score:',score)\n",
    "fpr,tpr,_=roc_curve(y_test,y_pred_prob[:,1])\n",
    "plt.plot(fpr,tpr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_kernel_tune(kernel):\n",
    "    model=SVC(kernel=kernel,probability=True)\n",
    "    model=model.fit(X_train,y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    y_pred_prob=model.predict_proba(X_test)\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    score=roc_auc_score(y_test,y_pred)\n",
    "    report=classification_report(y_test,y_pred)\n",
    "    # fpr,tpr,_=roc_curve(y_test,y_pred_prob[:,1])\n",
    "    print(' SVC Model with kernel:', kernel)\n",
    "    print( '      *************.  ')\n",
    "    print(' The confusion Matrix')\n",
    "    sns.heatmap(cm,annot=True)\n",
    "    print(' The classification Report:\\n', report)\n",
    "    print(' The ROC-AUC-Score:',score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function\n",
    "\n",
    "SVC_kernel_tune('linear')\n",
    "SVC_kernel_tune('poly')\n",
    "SVC_kernel_tune('rbf')\n",
    "SVC_kernel_tune('sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning the regularisation parameter C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a fn with a list of C as the parameter\n",
    "\n",
    "def SVC_C_tuner(C_list):\n",
    "    for c in C_list:\n",
    "        model=SVC(kernel='linear',C=c)\n",
    "        model=model.fit(X_train,y_train)\n",
    "        y_pred=model.predict(X_test)\n",
    "        score=roc_auc_score(y_test,y_pred)\n",
    "        print(' The value of C:',c, 'The score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of C values:\n",
    "\n",
    "C_list=[0.1,1,2,3,4,5,10,15,20,25,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list=[18,19,21,22]\n",
    "SVC_C_tuner(C_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_list=[18,19,21,22]\n",
    "SVC_C_tuner(C_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree #Label Encoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt1 = DecisionTreeClassifier()\n",
    "dt1 = dt1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = dt2.predict(x_test)\n",
    "plt.figure(figsize=(15,5))\n",
    "cm=confusion_matrix(Y_test,ypred)\n",
    "sns.heatmap(cm,annot=True)\n",
    "report=classification_report(Y_test,ypred)\n",
    "score=roc_auc_score(Y_test,ypred)\n",
    "print(' Confusion Matrix:\\n',cm)\n",
    "print(' The report:\\n',report)\n",
    "print(' Score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualising the tree created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plot_tree(dt_1,filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini= 1- (39/120)*(39/120) - (37/120)*(37/120) -(44/120)*(44/120)\n",
    "\n",
    "print(' Gini:',gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_1.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_1.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Rules:\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "text = export_text(dt_1,feature_names=iris['feature_names'])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with criteria= entropy rest all same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_2=DecisionTreeClassifier(criterion='entropy',max_depth=4)\n",
    "dt_2=dt_2.fit(X_train,y_train)\n",
    "y_pred_2=dt_2.predict(X_test)\n",
    "cm_2=confusion_matrix(y_test,y_pred_2)\n",
    "sns.heatmap(cm_2,annot=True);\n",
    "plt.figure(figsize=(15,15))\n",
    "plot_tree(dt_2,filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)KNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "#K Nearest Neighbours\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "rfc2 = RandomForestClassifier()\n",
    "knn2 = KNeighborsClassifier()\n",
    "knn2.fit(x_train,Y_train)\n",
    "ypred = knn2.predict(x_test)\n",
    "plt.figure(figsize=(15,5))\n",
    "cm=confusion_matrix(Y_test,ypred)\n",
    "sns.heatmap(cm,annot=True)\n",
    "report=classification_report(Y_test,ypred)\n",
    "score=roc_auc_score(Y_test,ypred)\n",
    "print(' Confusion Matrix:\\n',cm)\n",
    "print(' The report:\\n',report)\n",
    "print(' Score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper parameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn_gs=GridSearchCV(knn, {'n_neighbors': range(2,8)})\n",
    "knn_gs.fit(X_train,y_train)\n",
    "knn_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the best model\n",
    "knn_best=KNeighborsClassifier(n_neighbors=2)\n",
    "knn_best.fit(X_train,y_train)\n",
    "report=classification_report(y_test,knn_best.predict(X_test))\n",
    "\n",
    "print(' Report:\\n', report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(random_state=100)\n",
    "rfc.fit(X_train,y_train)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm=confusion_matrix(y_test,rfc.predict(X_test))\n",
    "report=classification_report(y_test,rfc.predict(X_test))\n",
    "\n",
    "print('CM:\\n',cm)\n",
    "print('Report:\\n',report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper parameter tuning using GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc_gs=GridSearchCV(rfc,{'n_estimators':range(75,125),\n",
    "                        'criterion':['gini','entropy']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a revised RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_new=RandomForestClassifier(n_estimators=122, \n",
    "                               criterion='entropy',random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_new.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfromance\n",
    "\n",
    "cm=confusion_matrix(y_test,rfc_new.predict(X_test))\n",
    "report=classification_report(y_test,rfc_new.predict(X_test))\n",
    "\n",
    "print('CM:\\n',cm)\n",
    "print('Report:\\n',report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_new.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DF\n",
    "df=pd.DataFrame({'Feature':X.columns,'Feature Imp':rfc_new.feature_importances_})\n",
    "df\n",
    "df=df.sort_values(['Feature Imp'],ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding one column\n",
    "df['Feature Imp Cum']=df['Feature Imp'].cumsum()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=df['Feature Imp'],y=df['Feature'],data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc2 = AdaBoostClassifier(random_state=10)\n",
    "abc2.fit(x_train,Y_train)\n",
    "ypred = abc2.predict(x_test)\n",
    "plt.figure(figsize=(15,5))\n",
    "cm=confusion_matrix(Y_test,ypred)\n",
    "sns.heatmap(cm,annot=True)\n",
    "report=classification_report(Y_test,ypred)\n",
    "score=roc_auc_score(Y_test,ypred)\n",
    "print(' Confusion Matrix:\\n',cm)\n",
    "print(' The report:\\n',report)\n",
    "print(' Score:',score)\n",
    "\n",
    "\n",
    "# Hyper parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "abc_gs=GridSearchCV(abc,{'n_estimators':range(25,75),\n",
    "                        'learning_rate':[0,0.25,0.5,0.75,1]})\n",
    "abc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the best model using these values\n",
    "\n",
    "ada_best=AdaBoostClassifier(learning_rate=0.25,n_estimators=53,random_state=10)\n",
    "\n",
    "ada_best.fit(X_train,y_train)\n",
    "\n",
    "report=classification_report(y_test,ada_best.predict(X_test))\n",
    "\n",
    "print('Report:\\n',report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc2 = GradientBoostingClassifier(random_state=10)\n",
    "gbc2.fit(x_train,Y_train)\n",
    "ypred = gbc2.predict(x_test)\n",
    "plt.figure(figsize=(15,5))\n",
    "cm=confusion_matrix(Y_test,ypred)\n",
    "sns.heatmap(cm,annot=True)\n",
    "report=classification_report(Y_test,ypred)\n",
    "score=roc_auc_score(Y_test,ypred)\n",
    "print(' Confusion Matrix:\\n',cm)\n",
    "print(' The report:\\n',report)\n",
    "print(' Score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning\n",
    "\n",
    "gbc_gs=GridSearchCV(gbc,{'n_estimators':range(75,125),\n",
    "                        'max_depth':range(1,5),\n",
    "                        'learning_rate':[0,0.25,.5,.75,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_gs.best_params_\n",
    "# Build the best\n",
    "grad_best=GradientBoostingClassifier(learning_rate=0.25,max_depth=1, n_estimators=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report=classification_report(y_test,grad_best.predict(X_test))\n",
    "\n",
    "print('Report:\\n',report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) XG bost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost:\n",
    "#One hot encoding\n",
    "xg2=XGBClassifier()\n",
    "xg2.fit(x_train,Y_train)\n",
    "ypred = xg2.predict(x_test)\n",
    "plt.figure(figsize=(15,5))\n",
    "cm=confusion_matrix(Y_test,ypred)\n",
    "sns.heatmap(cm,annot=True)\n",
    "report=classification_report(Y_test,ypred)\n",
    "score=roc_auc_score(Y_test,ypred)\n",
    "print(' Confusion Matrix:\\n',cm)\n",
    "print(' The report:\\n',report)\n",
    "print(' Score:',score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare the results\n",
    "# The best result offerd by gbc\n",
    "\n",
    "gbc.feature_importances_\n",
    "df=pd.DataFrame({'Feature':X.columns,\n",
    "                'Imp':gbc.feature_importances_})\n",
    "df\n",
    "df=df.sort_values(['Imp'],ascending=False)\n",
    "df\n",
    "sns.barplot(x=df['Imp'],y=df['Feature'],data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameter tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': range(50,150,10),\n",
    "    'criterion':['gini','entropy']\n",
    "}\n",
    "rfc_gs = GridSearchCV(rfc1,param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=120,criterion='gini')\n",
    "rfc.fit(X_train,y_train)\n",
    "ypred = rfc_gs.predict(X_test)\n",
    "plt.figure(figsize=(15,5))\n",
    "cm=confusion_matrix(y_test,ypred)\n",
    "sns.heatmap(cm,annot=True)\n",
    "report=classification_report(y_test,ypred)\n",
    "score=roc_auc_score(y_test,ypred)\n",
    "print(' Confusion Matrix:\\n',cm)\n",
    "print(' The report:\\n',report)\n",
    "print(' Score:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering:\n",
    "K Means:\n",
    "from sklearn.cluster import KMeans\n",
    "ssd = []\n",
    "for k in range(1,25):\n",
    "  kmeans = KMeans(n_clusters=k, random_state=10)\n",
    "  kmeans.fit(x)\n",
    "  ssd.append(kmeans.inertia_)\n",
    "plt.plot(range(1,25),ssd);\n",
    "k_best = KMeans(n_clusters=4,random_state=10)\n",
    "k_best.fit(x)\n",
    "clusters = k_best.predict(x)\n",
    "\n",
    "DBSCAN:\n",
    "from sklearn.cluster import DBSCAN\n",
    "db= DBSCAN(eps=0.5,min_samples=5)\n",
    "db.fit(x)\n",
    "\n",
    "Dropping empty rows just in case:\n",
    "remove = [row for row in range(1,len(db),2)]\n",
    "ndb = db.drop(remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
